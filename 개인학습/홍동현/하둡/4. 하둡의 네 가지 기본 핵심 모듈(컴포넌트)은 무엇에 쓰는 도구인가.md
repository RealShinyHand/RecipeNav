# 하둡의 네 가지 컴포넌트 혹은 핵심 모듈(핵심 기술) 나열하기

<br>

- Hadoop Core Technologies(Hadoop Apache Framework Basic Modules)
  - 1. Hadoop Common[하둡 공통 모듈] : 라이브러리와 유틸리티 포함
  - 2. Hadoop Distributed File System[하둡 분산 파일 시스템] - HDFS : 여러 노드를 묶어 시스템을 구축  
  - 3. Distributed Data Processing Frameworks[분산 데이터 프로세스 프레임워크] - Map/Reduce : 구글의 인덱스 서치 기능 / 데이터를 소량의 데이터로 쪼개기에서 시작
  - 4. Resource Manager and Scheduler[자원 관리자 그리고 스케줄러] - YARN

<br>

# 핵심 모듈[1]-하둡의 공통 모듈-Hadoop Common Module

<br>

- Libraries, Utilities
- CLI Mini Cluster / Native Libraries / Proxy User / Rack Awareness / Secure Mode / Service Level Authorization / HTTP Authentication / Credential Provider API / Hadoop KMS / Tracing / Unix Shell Guide

- Native Hadoop Libraries
  - 하둡은 네이티브 라이브러리(*.so file 파일)들을 가르키며 압축된 이들을 컴파일을 함으로 사용할 수 있습니다. 한 예로 하둡의 문서에는  libhadoop.so는 '네이티브 하둡 라이브러리'라고 지정하고 있습니다.

  - 하둡은 성능 사유로 그리고 자바 구현의 비가용성(non-availability)을 이유로 어떤 컴포넌트들을 네이티브 구현을 돕습니다.

  - 네이티브 하둡 라이브러리(Native Hadoop Library)는 리눅스 버전(GNU/Linus Platform)에서 사용할 수 있는 아래 컴포넌트들을 포함합니다. 

<br>

- 가설(Hypothesis or Assumption)
  - Reliability
    - 다른 모듈과 함께 측정을 일관되게 의지할 수 있는 Reliability(의존도/연계성) 가 하둡의 공통 분모입니다.

  - Fault Tolerance
    - 의존도에 대한 이야기를 할 때는 반드시 시스템 장애를 허용한다는 가설에서 하둡의 프로젝트 개발은 시작되었습니다.  그 말은 하둡 프레임워크 프로젝트 개발 당시 많은 노드들, 곧 머신들이라고 말하는데 이러한 HDFS 클러스트들이 3 개 이상 노드들(머신들)이 자동의 복사되도록 설계하였습니다. 그 노드들 안에는 서로 다른 머신 상에서 데이터 블럭(Data Block)들이 존재합니다. 사용자들은 원시 데이터가 저장된 해당 데이터들을 데이터 블럭들 사이로 세 개 이상 복제되어 저장함으로 시스템 장애 발생시 시스템이 자동적으로 복구하여 도와주는 기능을 볼 수 있습니다.

<br>

# 핵심 모듈[2]-하둡 분산 처리 파일 시스템 모듈(Hadoop Distributed File System)-HDFS Module

<br>

- HDFS의 일반적인 정의
  - 데이터는 HDFS 시스템 안에서 조직적으로 마련된 블럭들 안으로 배열되어집니다.
  - 그 블럭들은 투명하게 복제 됩니다.
  - 인텔리전트 복제 매커니즘을 통하여 데이터를 복수의 렉 (Multiple Racks) 형태로 구성된 노드들로 저장되어집니다.(최적화) 단순 복수의 데이터들이 노드들로 저장되는 것이 아닙니다.

<br>

- HDFS 시스템 디자인의 가설문
  - 이는 HDFS 설계를 구상할 때 세 가지 문구를 토대로 개발을 하게 되어 하둡이 탄생하게 됩니다.
    - HDFS 설계 가설[1] - 데이터가 적재된 파일을 순차적으로 풀 스케닝 합니다. 
    - HDFS 설계 가설[2] -  데이터가 저장된 노드들을 찾아서 각각 노드별로 계산을 수행하여 결과를 보여줍니다. 데이터를 뒤져서 가지고와서야 비로서 계산을 수행하는 관계형 데이터들과는 사뭇 다릅니다.
    - HDFS 설계 가설[3] -  노드들 중 어느 하나가 연산 수행에 장애를 가질 경우 하드웨어를 교체하여 성능을 향상시키는 고전적인 방법 대신 소프트웨어 레이어를 높여 처리하는 방식을 가지고 있습니다.

<br>

- HDFS 시스템의 세 가지 특징
  - Data Locality (데이터 지역성) 
  - Replicated Blocks (복제 블럭)  
  - High Probability (높은 가능성)

<br>

- HDFS 시스템 아키텍쳐 상위 계층 구조
  - 네임 노드 - 데이터 노드들의 위치나 데이터 내용에 대한 구성을 가진 한 개의 노드로 구성
  - 데이터 노드 - 데이터 수집된 다량의 내용을 가진 데이터 노드

<br>

# 핵심 모듈[3]-맵리듀스 모듈-MapReduce Module

<br>

- 맵리듀스 프레임워크 도입 유래

<br>

- 맵리듀스의 세 가지 단계 연산 처리 방식
  - 분산처리 모델
  - 맵 : 원시 데이터를 받아 key/value쌍으로 변환하고 HDFS 시스템에 저장
  - 리듀스 : 데이터셋을 작은 단위의 튜플셋으로 합침 / 이뮤터블 데이터 타입으로 만듬

<br>

- The definition of the Distributed Process Model 
  - Map Phase(로우 데이터를 key/value 방식으로 정리 / 클러스터로 병렬처리) -> Shuffle Phase(로우 데이터를 정렬된 키를 기준으로 같은 키를 가지는 리듀서로 이동) -> Reduce Phase(모든 키값을 위한 value를 처리 / HDFS나 다른 저장소로 저장)

<br>

- 분산 데이터 처리 프레임워크 맵리듀스의 워크플로우 단계
  - Input Data -> Data Split -> Map Phases -> Combine input data on partition -> Reduce

<br>


# 핵심 모듈[4]-얀 모듈-YARN Modules

<br>

- YARN 핵심 모듈
  - 스케줄링과 자우너관리

<br>

- YARN's  Two Components
  - The Allocation of Compute Resources
  - The Scheduler of user Application

<br>

- YARN's Four Core Management
  - Scheduler(자원관리 / 데이터 지역성), Container Management(CPU, Memory Level 등의 자원이 초과되지 않는지 관리), Data Locality(데이터 지역성 자체를 자원으로 관리), Container Isolation(독립성)
